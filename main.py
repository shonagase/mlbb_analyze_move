import streamlit as st
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import yt_dlp
import os
import tempfile
import torch
import traceback
import json
from datetime import datetime

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="MLBB Move Analyzer",
    page_icon="ğŸ®",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«
st.title("MLBB Move Analyzer")
st.subheader("Mobile Legends: Bang Bangã®è©¦åˆå‹•ç”»ã‚’åˆ†æã™ã‚‹ãƒ„ãƒ¼ãƒ«")

# çµæœä¿å­˜ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
RESULTS_DIR = Path("/Users/shoyanagatomo/Documents/git/mlbb_analyze_move/data/output")
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("è¨­å®š")
    confidence_threshold = st.slider(
        "æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05
    )
    
    tracking_enabled = st.checkbox("ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=True)
    save_results = st.checkbox("åˆ†æçµæœã‚’ä¿å­˜ã™ã‚‹", value=True)

# å…¥åŠ›æ–¹æ³•ã®é¸æŠ
input_method = st.radio(
    "å‹•ç”»ã®å…¥åŠ›æ–¹æ³•ã‚’é¸æŠ",
    ["YouTubeãƒªãƒ³ã‚¯", "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"]
)

video_path = None
video_info = {}

if input_method == "YouTubeãƒªãƒ³ã‚¯":
    youtube_url = st.text_input("YouTubeã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if youtube_url:
        try:
            with st.spinner("å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                # yt-dlpã®è¨­å®š
                temp_dir = tempfile.mkdtemp()
                video_path = os.path.join(temp_dir, "youtube_video.mp4")
                
                ydl_opts = {
                    'format': 'best[ext=mp4]',
                    'outtmpl': video_path,
                    'quiet': True,
                    'no_warnings': True,
                }
                
                # å‹•ç”»æƒ…å ±ã®å–å¾—
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(youtube_url, download=False)
                    video_info = {
                        "title": info.get('title', 'Unknown'),
                        "duration": info.get('duration', 0),
                        "view_count": info.get('view_count', 0),
                        "url": youtube_url
                    }
                    st.write(f"ã‚¿ã‚¤ãƒˆãƒ«: {video_info['title']}")
                    st.write(f"é•·ã•: {video_info['duration']} ç§’")
                    st.write(f"è¦–è´å›æ•°: {video_info['view_count']:,} å›")
                    
                    # å‹•ç”»ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    ydl.download([youtube_url])
                
                st.success("å‹•ç”»ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            video_path = None

else:
    uploaded_file = st.file_uploader("è©¦åˆã®å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['mp4', 'mov', 'avi'])
    if uploaded_file is not None:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        temp_dir = tempfile.mkdtemp()
        video_path = os.path.join(temp_dir, "uploaded_video.mp4")
        with open(video_path, "wb") as f:
            f.write(uploaded_file.read())
        video_info = {
            "title": uploaded_file.name,
            "file_size": uploaded_file.size,
            "type": uploaded_file.type
        }

# åˆ†æé–‹å§‹ãƒœã‚¿ãƒ³
if video_path and st.button("åˆ†æé–‹å§‹"):
    # åˆ†æçµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®è¾æ›¸
    analysis_data = {
        "video_info": video_info,
        "analysis_settings": {
            "confidence_threshold": confidence_threshold,
            "tracking_enabled": tracking_enabled
        },
        "frames": []
    }
    
    # ãƒ“ãƒ‡ã‚ªã®èª­ã¿è¾¼ã¿
    video = cv2.VideoCapture(video_path)
    
    # YOLOãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    with st.spinner("YOLOãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        model = YOLO('yolov8n.pt')
    
    # DeepSORTãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®åˆæœŸåŒ–ï¼ˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãŒæœ‰åŠ¹ãªå ´åˆï¼‰
    tracker = None
    if tracking_enabled:
        tracker = DeepSort(
            max_age=30,
            n_init=3,
            nms_max_overlap=1.0,
            max_cosine_distance=0.3,
            nn_budget=None,
            override_track_class=None,
            embedder="mobilenet",
            half=True,
            bgr=True,
            embedder_gpu=True
        )
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®è¡¨ç¤º
    progress_text = "å‹•ç”»ã‚’åˆ†æä¸­..."
    progress_bar = st.progress(0)
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã®å–å¾—
    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # çµæœã‚’è¡¨ç¤ºã™ã‚‹ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    result_placeholder = st.empty()
    
    frame_count = 0
    detections = []
    
    try:
        while video.isOpened():
            ret, frame = video.read()
            if not ret:
                break
                
            # YOLOã§æ¤œå‡º
            results = model(frame)[0]
            
            # æ¤œå‡ºçµæœã®å‡¦ç†
            frame_detections = []
            frame_data = {"frame_number": frame_count, "detections": [], "tracks": []}
            
            # boxeså±æ€§ãŒå­˜åœ¨ã—ã€ç©ºã§ãªã„å ´åˆã®ã¿å‡¦ç†
            if hasattr(results, 'boxes') and len(results.boxes) > 0:
                # ãƒ†ãƒ³ã‚½ãƒ«ã‚’numpyé…åˆ—ã«å¤‰æ›
                boxes = results.boxes.data.cpu().numpy()
                
                for box in boxes:
                    x1, y1, x2, y2, score, class_id = box
                    if score > confidence_threshold:
                        # DeepSORTãŒæœŸå¾…ã™ã‚‹å½¢å¼ã«å¤‰æ›
                        detection = [
                            [float(x1), float(y1), float(x2), float(y2)],
                            float(score),
                            int(class_id)
                        ]
                        frame_detections.append(detection)
                        
                        # åˆ†æçµæœã«æ¤œå‡ºæƒ…å ±ã‚’è¿½åŠ 
                        frame_data["detections"].append({
                            "bbox": [float(x1), float(y1), float(x2), float(y2)],
                            "score": float(score),
                            "class_id": int(class_id)
                        })
            
            # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            if tracking_enabled and tracker is not None and frame_detections:
                tracks = tracker.update_tracks(frame_detections, frame=frame)
                for track in tracks:
                    if not track.is_confirmed():
                        continue
                    track_id = track.track_id
                    ltrb = track.to_ltrb()
                    
                    # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµæœã‚’æç”»
                    cv2.rectangle(frame, 
                                (int(ltrb[0]), int(ltrb[1])), 
                                (int(ltrb[2]), int(ltrb[3])), 
                                (0, 255, 0), 2)
                    cv2.putText(frame, 
                              f"ID: {track_id}", 
                              (int(ltrb[0]), int(ltrb[1])-10), 
                              cv2.FONT_HERSHEY_SIMPLEX, 
                              0.9, 
                              (0, 255, 0), 
                              2)
                    
                    # åˆ†æçµæœã«ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æƒ…å ±ã‚’è¿½åŠ 
                    frame_data["tracks"].append({
                        "track_id": track_id,
                        "bbox": [float(x) for x in ltrb]
                    })
            
            # åˆ†æçµæœã«ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            if save_results:
                analysis_data["frames"].append(frame_data)
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æ›´æ–°
            progress = frame_count / total_frames
            progress_bar.progress(progress)
            
            # çµæœã‚’è¡¨ç¤º
            result_placeholder.image(
                cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),
                caption="åˆ†æçµæœ",
                use_container_width=True
            )
            
            frame_count += 1
    
    except Exception as e:
        st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.error(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°:\n{traceback.format_exc()}")
    
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        video.release()
        
        # åˆ†æçµæœã®ä¿å­˜
        if save_results:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_file = RESULTS_DIR / f"analysis_{timestamp}.json"
            with open(result_file, "w", encoding="utf-8") as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            st.success(f"åˆ†æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {result_file}")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤
        try:
            os.remove(video_path)
            os.rmdir(os.path.dirname(video_path))
        except:
            pass
    
    st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# ä¿å­˜ã•ã‚ŒãŸåˆ†æçµæœã®è¡¨ç¤º
if st.sidebar.checkbox("ä¿å­˜ã•ã‚ŒãŸåˆ†æçµæœã‚’è¡¨ç¤º"):
    saved_files = list(RESULTS_DIR.glob("*.json"))
    if saved_files:
        selected_file = st.sidebar.selectbox(
            "åˆ†æçµæœã‚’é¸æŠ",
            saved_files,
            format_func=lambda x: x.stem
        )
        
        if selected_file:
            with open(selected_file, "r", encoding="utf-8") as f:
                saved_data = json.load(f)
            
            st.subheader("å‹•ç”»æƒ…å ±")
            st.json(saved_data["video_info"])
            
            st.subheader("åˆ†æè¨­å®š")
            st.json(saved_data["analysis_settings"])
            
            st.subheader("ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æçµæœ")
            frame_number = st.slider("ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·", 0, len(saved_data["frames"])-1)
            st.json(saved_data["frames"][frame_number])
    else:
        st.sidebar.info("ä¿å­˜ã•ã‚ŒãŸåˆ†æçµæœã¯ã‚ã‚Šã¾ã›ã‚“") 